% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Reconocimiento de Entidades Nombradas}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Luis Ernesto Ibarra Vázquez\inst{1} \and
Luis Enrique Dalmau Coopat\inst{1}}
%
%\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Universidad de La Habana, La Habana, Cuba}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
%The abstract should briefly summarize the contents of the paper in
%150--250 words.

%TODO Agregarle algos obre NLP solo
La extracción de entidades nombradas consiste en la extracción y clasificación de entidades en un texto. Este documento presenta una definición del problema además de introducir los principales retos enfrentados en estos problemas y qué técnicas existen para darle una respuesta lo más acertada posible. 

\keywords{Entidades Nombradas  \and Aprendizaje de Máquina \and Procesamiento de Lenguaje Natural.}
\end{abstract}
%
%
%
\section{Introducción}

En el contexto actual con el desarrollo de las tecnologías, la explosión de información no estructurada en la web ha hecho que sea necesario un procesamiento para lograr extraer información por medios computacionales. De esto se encarga el Procesamiento de Lenguaje Natural, el cual es una rama de Inteligencia Artificial. Entre la información que se quiere extraer cuáles son las entidades que más significado semántico aportan al texto, una de esta información es saber las entidades que se encuentran en este y cuáles son las categorías a las que pertenece dicha entidad.

La solución de dicho problema traería consigo una manera de estructurar efectivamente muchos de estos documentos no estructurados pudiendo llegar a un estado de organización de los documentos presentes en la web agilizando diferentes tareas. En la recuperacion de información se pueden usar las entidades nombradas para mejorar el resultado obtenido por los buscadores, en la medicina se pueden encontrar las relaciones existentes entre diferentes entidades creando una base de datos que pueda servir como onotlogía para futuras consultas.

En el documento se presenta primero las dificultades generales del Procesamiento de Lenguaje Natural. Luego se introduce el tema sobre la Extracción de Entidades Nombradas y los algoritmos usados para resolverlos además de los problemas comunes que se enfrentan a la hora de la extracción de entidades.

\section{Procesamiento de Lenguaje Natural}

Últimamente estamos oyendo hablar mucho del procesamiento del lenguaje natural (NLP por sus siglas en inglés) y ahora más en este mundo digital. Sin embargo, el NLP es una disciplina que cuenta con más de 50 años de investigación y desarrollo.

¿Qué es el procesamiento de lenguaje natural?

El Procesamiento del Lenguaje Natural es el campo de conocimiento de la Inteligencia Artificial que se ocupa de investigar la manera de comunicar las máquinas con las personas mediante el uso de lenguas naturales, como el español, el inglés o el chino.

Virtualmente, cualquier lengua humana puede ser tratada por los ordenadores. Lógicamente, limitaciones de interés económico o práctico hace que solo las lenguas más habladas o utilizadas en el mundo digital tengan aplicaciones en uso.

Pensemos en cuántas lenguas hablan Siri (20) o Google Assistant (8). El inglés, español, alemán, francés, portugués, chino, árabe y japonés (no necesariamente en este orden) son las que cuentan con más aplicaciones que las entienden. Google Translate es la que más lenguas trata, superando el centenar… pero hay entre 5000 y 7000 lenguas en el mundo.

Las lenguas humanas pueden expresarse por escrito (texto), oralmente (voz) y también mediante signos. Naturalmente, el NLP está más avanzado en el tratamiento de textos, donde hay muchos más datos y son más fáciles de conseguir en formato electrónico.

Los audios, aunque estén en formato digital, hay que procesarlos para transcribirlos en letras o caracteres y, a partir de ahí, entender la pregunta. El proceso de respuesta es el inverso: primero se elabora la oración y luego se “sintetiza la voz”.

Por cierto, la voz artificial cada vez suena más humana, con inflexiones tonales y prosódicas que imitan la producción humana.[https://www.iic.uam.es/inteligencia/que-es-procesamiento-del-lenguaje-natural/]

Modelos para procesamiento del lenguaje natural

Tratar computacionalmente una lengua implica un proceso de modelización matemática. Los lingüistas computacionales se encargan de la tarea de “preparar” el modelo lingüístico para que posteriormente se implemente en un código eficiente y funcional. Básicamente, existen dos aproximaciones generales al problema de la modelización lingüística:

Modelos Lógicos: gramáticas

Los lingüistas escriben reglas de reconocimiento de patrones estructurales, empleando un formalismo gramatical concreto. Estas reglas, en combinación con la información almacenada en diccionarios computacionales, definen los patrones que hay que reconocer para resolver la tarea (buscar información, traducir, etc.).

Estos modelos lógicos pretenden reflejar la estructura lógica del lenguaje y surgen a partir de las teorías de N. Chomsky en los años 50. 


Modelos probabilísticos del lenguaje natural: basados en datos

La aproximación es a la inversa: los lingüistas recogen colecciones de ejemplos y datos (corpus) y a partir de ellos se calculan las frecuencias de diferentes unidades lingüísticas (letras, palabras, oraciones) y su probabilidad de aparecer en un contexto determinado. Calculando esta probabilidad, se puede predecir cuál será la siguiente unidad en un contexto dado, sin necesidad de recurrir a reglas gramaticales explícitas.

Es el paradigma de “aprendizaje automático” que se ha impuesto en las últimas décadas en Inteligencia Artificial: los algoritmos infieren las posibles respuestas a partir de los datos observados anteriormente en el corpus.
Componentes del procesamiento del lenguaje natural

A continuación, vemos algunos de los componentes del procesamiento del lenguaje natural. No todos los análisis que se describen se aplican en cualquier tarea de NLP, sino que depende del objetivo de la aplicación.

\begin{itemize}
    \item Análisis morfológico o léxico. Consiste en el análisis interno de las palabras que forman oraciones para extraer lemas, rasgos flexivos, unidades léxica compuestas. Es esencial para la información básica: categoría sintáctica y significado léxico.
    \item Análisis sintáctico. Consiste en el análisis de la estructura de las oraciones de acuerdo con el modelo gramatical empleado (lógico o estadístico).
    \item Análisis semántico. Proporciona la interpretación de las oraciones, una vez eliminadas las ambigüedades morfosintácticas.
    \item Análisis pragmático. Incorpora el análisis del contexto de uso a la interpretación final. Aquí se incluye el tratamiento del lenguaje figurado (metáfora e ironía) como el conocimiento del mundo específico necesario para entender un texto especializado.
\end{itemize}

Un análisis morfológico, sintáctico, semántico o pragmático se aplicará dependiendo del objetivo de la aplicación. Por ejemplo, un conversor de texto a voz no necesita el análisis semántico o pragmático. Pero un sistema conversacional requiere información muy detallada del contexto y del dominio temático.


 %HINT Características del procesamiento del Lenguaje Natural según su estructura y especificidades de cada idioma
 %HINT Dificultades en el procesamiento
 
En el ‘Introduction to Natural Language Processing‘ de Jacob Eisenstein.

En el primer capítulo, donde el autor aporta unas ideas de carácter general, dedica una ‘esquinita’ a mencionar cuatro problemáticas éticas del procesamiento del lenguaje natural. Son estas:

    Accesibilidad: Es decir, si el tratamiento del lenguaje se hace de forma general o para colectivos específicos. Por ejemplo, ¿Qué idiomas se tratan mediante lenguaje natural? ¿Puede abrir esto alguna forma de brecha digital entre países o culturas?
    Sesgos: Es uno de los problemas mencionados habitualmente en las consideraciones éticas sobre la Inteligencia Artificial. En este caso, y como hablamos específicamente de procesamiento de lenguaje natural, lo que el autor insinúa es que es posible que se trasladen al tratamiento automatizado del lenguaje sesgos existentes en nuestra forma de hablar, pensando, me imagino en, por ejemplo, ‘dejes’ no inclusivos de algún tipo.
    Fuerza de trabajo: Debo reconocer que no estoy seguro de entender del todo lo que plantea el autor en este caso concreto. En esencia, se pregunta dos cosas que no veo del todo conectadas. Por un lado, el origen de los conjuntos de datos y anotaciones sobre las que se trabaja para entrenar al algoritmo. Por otro, si el beneficio que se obtenga del procesamiento de lenguaje natural se comparte con todos aquellos que han aportado algo (no se si se refiere a trabajadores como tal, o a personas que han aportado sus conversaciones o textos l que conectaría con la primera cuestión).
    Privacidad y libertad de Internet: ¿Afecta el procesamiento de lenguaje natural a gran escala al derecho a comunicaciones privadas y gratuitas? ¿Qué papel puede jugar esta tecnología en regímenes totalitarios o intervencionistas?

No veo del todo nítidas todas las problemáticas que el autor intenta plantear pero me ha llamado la atención este foco ético en NLP que además me parece saludable. Seguiré atento al desarrollo que Eisenstein pueda hacer más adelante en el libro o que pueda encontrar en otra fuente.[Autor: Ignacio G.R. Gavilán  https://ignaciogavilan.com/cuatro-problemas-eticos-ligados-al-procesamiento-del-lenguaje-natural-nlp/]

\section{Entidad nombrada}

La definición de entidad nombrada se puede ver formalmente en los designadores rígidos\cite{rigid_designator}, los cuales son términos que designan la misma cosa en todos los mundos posibles en que esa cosa existe. Generalmente inluyen nombres propios y términos científicos tales como nombre de sustancias, elementos químicos. Esta definición es solo un punto de partida para el análisis de las entidades ya que se puede relajar  para abarcar más elementos como entidades, por ejemplo, las expresiones temporales y numéricas, como cantidades de dinero y unidades de medida, se toman como entidades nombradas. 

\subsection{Ejemplos}

\begin{itemize}

\item Universidad de La Habana: Entidad nombrada
\item universidad: No es una entidad nombrada, puede representar entidades diferentes.
\item Facultad de Matemática y Computación de la Universidad de La Habana: Entidad nombrada
\item UH: Entidad nombrada
\end{itemize}

\subsection{Problemas}

En los ejemplos anteriores se evidencian algunos de los problemas que tiene la extracción de entidades nombradas. En el \emph{Universidad de La Habana} se presentan dos entidades \emph{solapadas}, la entidad completa como organización y La Habana como lugar, sin embargo la más correcta es la de universidad como organización. Para mitigar este problema las entidades nombradas se toman como una sucesión de tokens que no se solapan. Otro problema reflejado en el ejemplo de \emph{universidad} es la falta de la capacidad de inferir a la entidad a la que se refieren, lo cual puede traer que se pierda mucha información en el análisis del texto. Además del problema de solapamiento, se encuentra el problema de las entidades anidadas. En el ejemplo de \emph{Facultad de Matemática y Computación de la Universidad de La Habana} se presentan dos entidades las cuales tienen sentido de manera independiente \emph{Facultad de Matemática y Computación} y \emph{Universidad de La Habana}, ver cuando estas entidades van juntas o separadas constituye un problema en la extracción de entidades.

\section{Categorías}

Las categorías son grupos a los que las entidades nombradas pertenecen. La variedad de estos grupos y su interrelacción entre ellos está dada principalmente por el contexto del problema a tratar. Las principales categorías son: \textbf{persona}, \textbf{organización} y \textbf{lugar}, estas se pueden encuentran en todo texto independientemente del tema que traten aunque existen varias definiciones de categorías llegando algunas incluso a formar jerarquías. Las categorías también pueden crearse en dependencia del contexto en que se vaya a procesar el texto, especializándolas más para lograr extraer información más exactas, esto ocurre principalmente en el campo de la química y la biología en la cual los nombres de las sustancias se califican en categorías afines. Un ejemplo de una definición general jerárquica se encuentra en la versión de \emph{Sekine}\cite{sekine} que cuenta con unos 200 subtipos.

\subsection{Ejemplos}

\begin{itemize}

\item Universidad de La Habana: Organización
\item La Habana: Lugar
\item Nombre Random: Persona %TODO Poner nombre de verdad :(

\end{itemize}

\subsection{Problemas}

La asingación de categorías a las entidades presentan varios problemas. Uno de ellos es seleccionar el conjunto de categorías en las que se va a mover las entidades nombradas, teniendo mucho peso el contexto del problema, por ejemplo si se está analizando un conjunto de datos sobre música, podrían ser relevantes tener las categorías de disquera, músico, etc, las cuales extraigan información relevante de los documentos. Un problema común es la propia ambigüedad del lenguaje, por ejemplo, en el caso de que exista una organización y un lugar llamados iguales se complica la clasificación de este ya que dado el contexto podría ser cualquiera de las dos. %TODO Poner ejemplo de esto

\section{Definición del problema de Extracción de Entidades Nombradas}

Dada las definiciones anteriores el problema de Reconocimiento de Entidades Nombradas se puede definir como la extracción y clasificación de las entidades nombradas de un texto. Como dice en la definición, el problema se divide en dos partes fundamentales: extracción y clasificación.

\subsection{Extracción de entidades}

La extracción de entidades consiste en extraer del texto las entidades existentes en él ya anotadas con diferentes metadatos como la parte de oración que represena, la posición dentro de una entidad entre otras. En este proceso intervienen dos etapas que se interrelacionan entre sí: \emph{chuncking}\cite{chunking} y \emph{Part-of-Speech (POS) Tagging}\cite{postag}.

\subsubsection{POS Tagging}

El objetivo de este subproblema es anotar una secuencia de tokens con la parte de la oración que representa, estas partes dependen del idioma y del conjunto seleccionado por el personal que realice el software en dependencia de la necesidad del software creado. En este caso nos enfocaremos en el idioma inglés en el cual existen 9 tipos de POS importantes de los que sobrealen: sustantivo, verbo, adjetivo, preposición, pronombre y adverbio. En la literatura existen otros conjuntos de etiquetas basados en las partes mencionadas anteriores pero que agregan otros datos como si se está en plural o singular, tiempo del verbo etc, entre estos se encuentran:

\begin{itemize}
\item Penn Treebank \cite{pennpostag}
\item Brown Corpus \cite{brownpostag}
\end{itemize}

Por ejemplo la frase \emph{I study at University of Havana} produce la siguiente salida: \emph{I|PRON study|VERB at|ADP University|PROPN of|ADP Havana|PROPN}.

Para resolver este problema se han ideado diferentes aproximaciones:

\begin{itemize}

\item Expersiones regulares: Las expresiones regulares son usadas principalemente a la hora de anotar cantidades de dinero o entidades que empiezan con honoríficos como Sr, Dr, MsC, entre otras en las cuales existe una alta probabilidad de que la anotación sea correcta.

\item Aprendizaje de máquina: Se han usado diferentes algoritmos para este problema como SVM, perceptron, nearest-neighbor, llegando a una precisión superior del 95\% \cite{postag}

\item Modelos ocultos de Markov (Hidden Marcov Models HMM): En el caso más simple este modelo se puede ver como un grafo dirigido en el cual los estados representan las partes de la oración y las aristas representan las posibles transiciones del estado actual al siguiente, estas aristas están ponderadas con la probabilidad de cuál es el estado siguiente. El estado no observable representa la etiqueta POS y el estado observable representa el token actual \cite{hmm}.

\end{itemize}

\subsubsection{Chunking}

%Esta etapa del proceso ocurre luego del POS-tagging y se encarga de agrupar los tokens antodados del POS en partes más significativas de la oración creando un árbol cuya raíz es el texto y las hojas los tokens anotados. Siguiendo el ejemplo: \emph{I|PRON study|VERB at|ADP University|PROPN of|ADP Havana|PROPN} se convierte en Fig.\ref{syntaxtree}
%
%\begin{figure}
%\includegraphics[width=\textwidth]{syntaxtree.jpg}
%\caption{Árbol de sintaxis} \label{syntaxtree}
%\end{figure}

%Sobre este árbol se realizan diferentes algoritmos para la extracción de entidades nombradas:

Esta etapa se puede ver como un problema de segmentación en la cual se quiere particionar los tokens anotados previemente con las etiquetas POS en conjuntos que identifiquen las entidades nombradas.

\begin{figure}
\includegraphics[width=\textwidth]{namedentity.jpg}
\caption{Chunking} \label{chunkingfig}
\end{figure}

Para lograr esta anotación se utilizan varias aproximaciones:

\begin{itemize}

\item Gramáticas: Se les da gramáticas en las que los términos finales son las anotaciones de la parte de la
oración y luego son parseadas en dependencia de estas. Algunos parsers proveen la capacidad de 
tener expresiones regulares en su interior aumentando la expresividad \cite{nltkgrammar}

\item Aprendizaje de Máquina: Generalmente se realiza un aprendizaje supervisado mediante un conjunto de datos, las entradas del conjunto de datos varían pero las más simples es una tupla \emph{(palabra, IOB tag)}.  IOB es una anotación va acompañada en cada token y representa si una parte esta dentro (In), fuera (Outside) o inicio (Begining) de un pedazo o entidad.

\end{itemize}

\subsection{Clasificación de entidades}

Esta parte del problema es la encargada de clasificar todas las entidades extraídas del texto en las diferentes categorías seleccionadas. La más ampliamente usada es aprendizaje de máquina, en esta se utiliza el aprendizaje supervisado para elaborar una función que dada un texto anotado devuelva las categorías a las que pertenecen estas, entre los algoritmos que se pueden utilizar encuentran:

\begin{itemize}

\item K-Nearest Neighbor
\item Árboles de decisión
\item Naive Bayes
\item Random Forest
\item Regresión Logística (Con estrategias para soportar múltiples clases)
\item SVM (Con estrategias para soportar múltiples clases)

\end{itemize}


\section{Problemas}

La extracción de entidades nombradas incurren en diferentes problemas uno de ellos está relacionado principalmente con el corpus usado para el entrenamiento del sistema. En general los corpus existentes se han entrenado en un ambiente relativamente cerrado y uniforme, por ejemplo, Wikipedia, periódicos, artículos científicos. Esto tiene como consecuencia que si se usa este sistema en un ambiente no relacionado o estructurado de manera similar el rendimiento baje. Un ejemplo clásico en el cual esto ocurre es en Twitter, debido a la gran cantidad de temas en los que se habla, la cantidad limitada de 140 caracteres, la ausencia de reglas para escribir,  entre otros elementos hace que los NER se desempeñen de manera pobre. Este problema es abordado en \cite{tweeter}, en este artículo sus escritores lograron reducir los errores en el POS hasta un 41\% con respecto al Standford POS Tagger y logrando una métrica F1 final de 0.59 en comparación con 0.29 del Standford NER.

Otro problema relacionado con el corpus es el inherente error humano y la propia ambigüedad del lenguaje, esto hace que en oraciones con la misma sintaxis y semántica las anotaciones difieran por errores humanos, pudiendo llevar en el peor de los casos a variar el rendimiento del sistema en un 5\% \cite{posdecisiontree}. Aunque en general los anotadores humanos son hasta ahora la manera más fiable de obtener información anotada correctamente, esto requiere del trabajo manual de estos lo cual se hace en muchos casos impracticable debido al gran volumen de datos que se procesa hoy en día.

\section{Usos}

%TODO Poner usos

\section{Conclusiones}

%TODO Poner conclusiones

%\subsubsection{Sample Heading (Third Level)} Only two levels of
%headings should be numbered. Lower level headings remain unnumbered;
%they are formatted as run-in headings.
%
%\paragraph{Sample Heading (Fourth Level)}
%The contribution should contain no more than four levels of
%headings. Table~\ref{tab1} gives a summary of all heading levels.
%
%\begin{table}
%\caption{Table captions should be placed above the
%tables.}\label{tab1}
%\begin{tabular}{|l|l|l|}
%\hline
%Heading level &  Example & Font size and style\\
%\hline
%Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
%1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
%2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
%3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
%4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
%\hline
%\end{tabular}
%\end{table}
%
%
%\noindent Displayed equations are centered and set on a separate
%line.
%\begin{equation}
%x + y = z
%\end{equation}
%Please try to avoid rasterized images for line-art diagrams and
%schemas. Whenever possible, use vector graphics instead (see
%Fig.~\ref{fig1}).
%
%\begin{figure}
%\includegraphics[width=\textwidth]{userPhoto.jpg}
%\caption{A figure caption is always placed below the illustration.
%Please note that short captions are centered, while long ones are
%justified by the macro package automatically.} \label{fig1}
%\end{figure}
%
%\begin{theorem}
%This is a sample theorem. The run-in heading is set in bold, while
%the following text appears in italics. Definitions, lemmas,
%propositions, and corollaries are styled the same way.
%\end{theorem}
%%
%% the environments 'definition', 'lemma', 'proposition', 'corollary',
%% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%%
%\begin{proof}
%Proofs, examples, and remarks have the initial word in italics,
%while the following text appears in normal font.
%\end{proof}
%For citations of references, we prefer the use of square brackets
%and consecutive numbers. Citations using labels or the author/year
%convention are also acceptable. The following bibliography provides
%a sample reference list with entries for journal
%articles~\cite{ref_article1}, an LNCS chapter~\cite{ref_lncs1}, a
%book~\cite{ref_book1}, proceedings without editors~\cite{ref_proc1},
%and a homepage~\cite{ref_url1}. Multiple citations are grouped
%\cite{ref_article1,ref_lncs1,ref_book1},
%\cite{ref_article1,ref_book1,ref_proc1,ref_url1}.
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}
%\bibitem{ref_article1}
%Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)
%
%\bibitem{ref_lncs1}
%Author, F., Author, S.: Title of a proceedings paper. In: Editor,
%F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
%Springer, Heidelberg (2016). \doi{10.10007/1234567890}
%
%\bibitem{ref_book1}
%Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
%Location (1999)
%
%\bibitem{ref_proc1}
%Author, A.-B.: Contribution title. In: 9th International Proceedings
%on Proceedings, pp. 1--2. Publisher, Location (2010)

\bibitem{sekine}
New York University, Natural Language Processing Section, \url{https://nlp.cs.nyu.edu/ene/version7\_1\_0Beng.html}. Accedido 13
de abril 2022

\bibitem{rigid_designator}
Wikipedia, \url{https://en.wikipedia.org/wiki/Rigid\_designator}. Accedido 13
de abril 2022

\bibitem{chunking}
Wikipedia, \url{https://en.wikipedia.org/wiki/Shallow\_parsing}. Accedido 12 de abril
2022

\bibitem{postag}
Wikipedia, \url{https://en.wikipedia.org/wiki/Part-of-speech\_tagging}. Accedido 13 de abril
2022

\bibitem{pennpostag}
University of Pensilvania Departament of Linguistics, \url{https://www.ling.upenn.edu/courses/Fall\_2003/ling001/penn\_treebank\_pos.html}. Accedido 13 de abril 2022

\bibitem{hmm}
Towards Data Science, \url{https://towardsdatascience.com/part-of-speech-tagging-for-beginners-3a0754b2ebba}. Accedido 13 de abril
2022

\bibitem{brownpostag}
Wikipedia, \url{https://en.wikipedia.org/wiki/Brown\_Corpus\#Part-of-speech\_tags\_used}. Accedido 13 de abril 2022

\bibitem{ref_url1}
LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
Oct 2017

\bibitem{nltkgrammar}
Steven Bird, Ewan Klein, and Edward Loper: Natural Language Processing with Python. Online Edition. \url{https://www.nltk.org/book/ch07.html}

\bibitem{tweeter}
Alan Ritter, Sam Clark, Mausam and Oren Etzioni: Named Entity Recognition in Tweets:
An Experimental Study. University of Washington Seattle, WA 98125, USA

\bibitem{posdecisiontree}
Lluís Màrquez i Villodre: Part-of-speech Tagging: A Machine Learning Approach based on Decision Trees. Departament de Llenguatges i Sistemes Informàtics de la Universitat Politècnica de Catalunya, Barcelona (1999)


\end{thebibliography}
\end{document}
